"""
Tone & Manner Engine Demo
ãƒˆãƒ³ãƒãƒŠä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import sys
import os
from datetime import datetime, timedelta

# Add the src directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

try:
    from content.tone_manner_engine import (
        ToneMannerEngine,
        BrandVoiceProfile,
        ToneType,
        FormalityLevel,
        WritingStyle
    )
    from content.content_management_system import (
        ArticleContent,
        ToneManner
    )
    
    print("ğŸ¨ Tone & Manner Engine Demo - Phase 5 Implementation")
    print("=" * 60)
    
    # Tone & Manner EngineåˆæœŸåŒ–
    tone_engine = ToneMannerEngine()
    print("âœ… Tone & Manner Engine initialized")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    brand_profile = BrandVoiceProfile(
        brand_name="èŠ±ã®å°‚é–€ã‚µã‚¤ãƒˆ",
        preferred_tone=ToneType.FRIENDLY,
        preferred_formality=FormalityLevel.CASUAL,
        preferred_writing_style=WritingStyle.INFORMATIVE,
        target_audience="èŠ±å¥½ãã®å¥³æ€§ï¼ˆ20-50ä»£ï¼‰",
        brand_keywords=["ç¾ã—ã„", "ç™’ã—", "è‡ªç„¶", "å„ªé›…", "å¿ƒåœ°ã‚ˆã„"],
        avoid_keywords=["é›£ã—ã„", "è¤‡é›‘", "å°‚é–€çš„ã™ãã‚‹"],
        voice_characteristics={
            "warmth": 0.8,
            "professionalism": 0.6,
            "friendliness": 0.9,
            "expertise": 0.7,
            "accessibility": 0.8
        },
        style_guidelines={
            "use_honorifics": False,
            "use_casual_expressions": True,
            "include_seasonal_references": True,
            "focus_on_emotions": True
        }
    )
    
    tone_engine.set_brand_voice_profile(brand_profile)
    print("âœ… Brand voice profile configured")
    
    # ä¸€è²«ã—ãŸãƒˆãƒ³ãƒãƒŠã®éå»è¨˜äº‹ã‚’è¿½åŠ 
    consistent_tone = ToneManner(
        tone="è¦ªã—ã¿ã‚„ã™ã„",
        formality="ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«",
        target_audience="èŠ±å¥½ãã®å¥³æ€§",
        writing_style="æƒ…å ±æä¾›å‹"
    )
    
    historical_articles = [
        ArticleContent(
            id="hist_1",
            title="1æœˆã®èª•ç”ŸèŠ±ã€Œã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã€ã§å¿ƒã‚‚æ¸©ã¾ã‚‹å†¬ã®å½©ã‚Š",
            content="å¯’ã„å†¬ã«ã‚‚ç¾ã—ãå’²ãã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€1æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦å¤šãã®äººã«æ„›ã•ã‚Œã¦ã„ã¾ã™ã€‚ãã®æ¸©ã‹ã¿ã®ã‚ã‚‹è‰²åˆã„ã¯ã€è¦‹ã‚‹äººã®å¿ƒã‚’å„ªã—ãåŒ…ã¿è¾¼ã‚“ã§ãã‚Œã¾ã™ã­ã€‚ãŠéƒ¨å±‹ã«é£¾ã‚‹ã¨ã€ä¸€æ°—ã«æ˜ã‚‹ã„é›°å›²æ°—ã«ãªã‚Šã¾ã™ã‚ˆã€‚",
            keyword="1æœˆ èª•ç”ŸèŠ± ã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=30)
        ),
        ArticleContent(
            id="hist_2",
            title="2æœˆã®èª•ç”ŸèŠ±ã€Œãƒ—ãƒªãƒ ãƒ©ã€ãŒé‹ã¶æ˜¥ã®ä¾¿ã‚Š",
            content="å¯æ†ãªãƒ—ãƒªãƒ ãƒ©ã¯ã€2æœˆã®ä»£è¡¨çš„ãªèª•ç”ŸèŠ±ã¨ã—ã¦è¦ªã—ã¾ã‚Œã¦ã„ã¾ã™ã€‚å°ã•ãªèŠ±ã³ã‚‰ãŒé›†ã¾ã£ã¦å’²ãå§¿ã¯ã€ã¾ã‚‹ã§æ˜¥ã®å¦–ç²¾ã®ã‚ˆã†ã§ã™ã­ã€‚è‰²ã¨ã‚Šã©ã‚Šã®èŠ±è‰²ã¯ã€ã¾ã å¯’ã„å­£ç¯€ã«å¿ƒæ¸©ã¾ã‚‹å½©ã‚Šã‚’ä¸ãˆã¦ãã‚Œã¾ã™ã€‚",
            keyword="2æœˆ èª•ç”ŸèŠ± ãƒ—ãƒªãƒ ãƒ©",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=20)
        ),
        ArticleContent(
            id="hist_3",
            title="3æœˆã®èª•ç”ŸèŠ±ã€Œæ¡œã€ã§æ„Ÿã˜ã‚‹æ—¥æœ¬ã®ç¾ã—ã•",
            content="æ—¥æœ¬äººã«ã¨ã£ã¦ç‰¹åˆ¥ãªèŠ±ã€æ¡œã€‚3æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦ã‚‚çŸ¥ã‚‰ã‚Œã€ãã®ç¾ã—ã•ã¯å¤šãã®äººã®å¿ƒã‚’é­…äº†ã—ç¶šã‘ã¦ã„ã¾ã™ã€‚æ·¡ã„ãƒ”ãƒ³ã‚¯ã®èŠ±ã³ã‚‰ãŒèˆã„æ•£ã‚‹æ§˜å­ã¯ã€æ—¥æœ¬ãªã‚‰ã§ã¯ã®ç¾æ„è­˜ã‚’æ„Ÿã˜ã•ã›ã¦ãã‚Œã¾ã™ã­ã€‚",
            keyword="3æœˆ èª•ç”ŸèŠ± æ¡œ",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=10)
        )
    ]
    
    print("\nğŸ“š éå»è¨˜äº‹è¿½åŠ ãƒ†ã‚¹ãƒˆ")
    for article in historical_articles:
        tone_engine.add_historical_article(article)
    print(f"   è¿½åŠ å®Œäº†: {tone_engine.get_historical_articles_count()}ä»¶ã®éå»è¨˜äº‹")
    
    # ===== ä¸€è²«ã—ãŸè¨˜äº‹ã®åˆ†æ =====
    print("\nâœ… ä¸€è²«ã—ãŸãƒˆãƒ³ãƒãƒŠè¨˜äº‹ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    consistent_article = ArticleContent(
        id="consistent_test",
        title="4æœˆã®èª•ç”ŸèŠ±ã€Œæ¡œè‰ã€ã®æ„›ã‚‰ã—ã„é­…åŠ›",
        content="æ˜¥ã‚‰ã—ã„æ¡œè‰ã¯ã€4æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦è¦ªã—ã¾ã‚Œã¦ã„ã¾ã™ã€‚å°ã•ãã¦å¯æ„›ã‚‰ã—ã„èŠ±ã¯ã€è¦‹ã¦ã„ã‚‹ã ã‘ã§å¿ƒãŒç™’ã•ã‚Œã¾ã™ã­ã€‚ã‚¬ãƒ¼ãƒ‡ãƒ‹ãƒ³ã‚°åˆå¿ƒè€…ã®æ–¹ã§ã‚‚è‚²ã¦ã‚„ã™ãã€æ˜¥ã®ãŠåº­ã‚’ç¾ã—ãå½©ã£ã¦ãã‚Œã¾ã™ã‚ˆã€‚",
        keyword="4æœˆ èª•ç”ŸèŠ± æ¡œè‰",
        tone_manner=consistent_tone,
        created_at=datetime.now()
    )
    
    analysis = tone_engine.analyze_tone_manner(consistent_article)
    print(f"   ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {analysis.consistency_score:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³ä¸€è‡´: {analysis.target_tone_match}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è‡´: {analysis.formality_match}")
    print(f"   æ–‡ä½“ä¸€è‡´: {analysis.style_match}")
    print(f"   ä¸ä¸€è‡´ä»¶æ•°: {len(analysis.inconsistencies)}")
    
    # ===== ä¸ä¸€è‡´è¨˜äº‹ã®åˆ†æ =====
    print("\nâš ï¸ ä¸ä¸€è‡´ãƒˆãƒ³ãƒãƒŠè¨˜äº‹ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    inconsistent_article = ArticleContent(
        id="inconsistent_test",
        title="èª•ç”ŸèŠ±ã«é–¢ã™ã‚‹å­¦è¡“çš„è€ƒå¯Ÿ",
        content="èª•ç”ŸèŠ±ã®æ¦‚å¿µã«ã¤ãã¾ã—ã¦ã¯ã€ãã®èµ·æºã‚’19ä¸–ç´€ã®ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã«æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¤ç‰©å­¦çš„è¦³ç‚¹ã‹ã‚‰ç”³ã—ä¸Šã’ã¾ã™ã¨ã€å„æœˆã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸèŠ±å‰ã¯ã€ãã®æ™‚æœŸã®æ°—å€™æ¡ä»¶åŠã³æ ½åŸ¹é©æ€§ã‚’è€ƒæ…®ã—ã¦é¸å®šã•ã‚Œã¦ãŠã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®è¤‡é›‘ãªå°‚é–€çš„è¦å› ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯æ¥µã‚ã¦å›°é›£ã§ã‚ã‚Šã¾ã™ã€‚",
        keyword="èª•ç”ŸèŠ± å­¦è¡“ ç ”ç©¶",
        tone_manner=ToneManner(
            tone="ãƒ•ã‚©ãƒ¼ãƒãƒ«",
            formality="éå¸¸ã«ä¸å¯§",
            target_audience="ç ”ç©¶è€…ãƒ»å°‚é–€å®¶",
            writing_style="å­¦è¡“çš„"
        ),
        created_at=datetime.now()
    )
    
    inconsistent_analysis = tone_engine.analyze_tone_manner(inconsistent_article)
    print(f"   ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {inconsistent_analysis.consistency_score:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³ä¸€è‡´: {inconsistent_analysis.target_tone_match}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è‡´: {inconsistent_analysis.formality_match}")
    print(f"   æ–‡ä½“ä¸€è‡´: {inconsistent_analysis.style_match}")
    print(f"   ä¸ä¸€è‡´ä»¶æ•°: {len(inconsistent_analysis.inconsistencies)}")
    
    # ä¸ä¸€è‡´è©³ç´°ã®è¡¨ç¤º
    print("   æ¤œå‡ºã•ã‚ŒãŸä¸ä¸€è‡´:")
    for inc in inconsistent_analysis.inconsistencies:
        print(f"     - {inc.severity}: {inc.description}")
    
    # ===== ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡ =====
    print("\nğŸ¯ ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡ãƒ†ã‚¹ãƒˆ")
    brand_compliance = tone_engine.evaluate_brand_voice_compliance(consistent_article)
    print(f"   ç·åˆé©åˆåº¦: {brand_compliance['overall_compliance_score']:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³é©åˆåº¦: {brand_compliance['tone_compliance']:.3f}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«é©åˆåº¦: {brand_compliance['formality_compliance']:.3f}")
    print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©åˆåº¦: {brand_compliance['keyword_compliance']:.3f}")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨åˆ†æ
    print("\nğŸ” ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨åˆ†æãƒ†ã‚¹ãƒˆ")
    keyword_usage = tone_engine.analyze_brand_keyword_usage(consistent_article.content)
    print(f"   ä½¿ç”¨ã•ã‚ŒãŸãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword_usage['used_brand_keywords']}")
    print(f"   é¿ã‘ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {keyword_usage['avoided_keywords_found']}")
    print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨ã‚¹ã‚³ã‚¢: {keyword_usage['keyword_usage_score']:.3f}")
    
    # ===== ä¿®æ­£ææ¡ˆç”Ÿæˆ =====
    print("\nğŸ’¡ ä¿®æ­£ææ¡ˆç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    recommendations = tone_engine.generate_tone_recommendations(inconsistent_article)
    print(f"   ç”Ÿæˆã•ã‚ŒãŸææ¡ˆ: {len(recommendations)}ä»¶")
    for i, rec in enumerate(recommendations[:3], 1):
        print(f"     {i}. {rec.priority}å„ªå…ˆåº¦: {rec.explanation}")
    
    # ===== æ•¬èªèª¿æ•´ææ¡ˆ =====
    print("\nğŸ”„ æ•¬èªèª¿æ•´ææ¡ˆãƒ†ã‚¹ãƒˆ")
    formal_text = "ç”³ã—ä¸Šã’ã¾ã™ãŒã€ã“ã®èŠ±ã«ã¤ãã¾ã—ã¦ã¯ã”èª¬æ˜ã•ã›ã¦ã„ãŸã ãã¾ã™"
    formality_suggestions = tone_engine.suggest_formality_adjustments(formal_text)
    print(f"   å…ƒã®æ–‡ç« : {formal_text}")
    print("   èª¿æ•´ææ¡ˆ:")
    for i, suggestion in enumerate(formality_suggestions, 1):
        print(f"     {i}. {suggestion}")
    
    # ===== è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ =====
    print("\nğŸ†• è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆãƒ†ã‚¹ãƒˆ")
    old_text = "ã‹ã‚ˆã†ãªç¾ã—ãèŠ±ã‚’æ‹è¦‹ã„ãŸã—ã¾ã™ã¨ã€å¿ƒãŒæ´—ã‚ã‚Œã‚‹æ€ã„ã§ã”ã–ã„ã¾ã™"
    modern_suggestions = tone_engine.suggest_expression_modernization(old_text)
    print(f"   å…ƒã®æ–‡ç« : {old_text}")
    print("   ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ:")
    for i, suggestion in enumerate(modern_suggestions, 1):
        print(f"     {i}. {suggestion}")
    
    # ===== è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ =====
    print("\nğŸ“Š è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãƒ†ã‚¹ãƒˆ")
    expression_patterns = tone_engine.analyze_expression_patterns()
    print(f"   å…±é€šè¡¨ç¾: {expression_patterns['common_expressions'][:3]}")
    print(f"   æ„Ÿæƒ…èª: {expression_patterns['emotional_words'][:5]}")
    
    # ===== æ–‡æ§‹é€ åˆ†æ =====
    print("\nğŸ“ æ–‡æ§‹é€ åˆ†æãƒ†ã‚¹ãƒˆ")
    sentence_analysis = tone_engine.analyze_sentence_structure(consistent_article.content)
    print(f"   æ–‡æ•°: {sentence_analysis['sentence_count']}")
    print(f"   å¹³å‡æ–‡é•·: {sentence_analysis['average_sentence_length']:.1f}æ–‡å­—")
    print(f"   æœ€çŸ­æ–‡: {sentence_analysis['shortest_sentence']}æ–‡å­—")
    print(f"   æœ€é•·æ–‡: {sentence_analysis['longest_sentence']}æ–‡å­—")
    
    # ===== ä¸€è²«æ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ =====
    print("\nğŸ“‹ ä¸€è²«æ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    all_articles = historical_articles + [consistent_article, inconsistent_article]
    consistency_report = tone_engine.generate_consistency_report(all_articles)
    print(f"   å…¨ä½“ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {consistency_report.overall_consistency_score:.3f}")
    print(f"   åˆ†æè¨˜äº‹æ•°: {len(consistency_report.article_analyses)}")
    print(f"   ã‚ˆãã‚ã‚‹ä¸ä¸€è‡´: {[inc.value for inc in consistency_report.common_inconsistencies[:3]]}")
    print(f"   ç·åˆæ¨å¥¨äº‹é …: {len(consistency_report.recommendations)}ä»¶")
    
    # ===== ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡ =====
    print("\nğŸ“ˆ ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆ")
    tone_evolution = tone_engine.track_tone_evolution()
    print(f"   ãƒˆãƒ¼ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜éŒ²: {len(tone_evolution['tone_trends'])}ä»¶")
    print(f"   æ–‡ä½“å¤‰åŒ–: {len(tone_evolution['style_changes'])}ä»¶")
    
    print("\nğŸ‰ Tone & Manner Engine - å…¨æ©Ÿèƒ½å®Ÿè£…å®Œäº†!")
    print("=" * 60)
    print("âœ… éå»è¨˜äº‹ã¨ã®ãƒˆãƒ³ãƒãƒŠæ¯”è¼ƒ")
    print("âœ… æ–‡ä½“ãƒ»è¡¨ç¾ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯")
    print("âœ… ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡")
    print("âœ… ä¿®æ­£ææ¡ˆç”Ÿæˆ")
    print("âœ… æ•¬èªèª¿æ•´ææ¡ˆ")
    print("âœ… è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ")
    print("âœ… ä¸€è²«æ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print("âœ… ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡")
    
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("Missing dependencies - this is expected in test environment")
    
except Exception as e:
    print(f"âŒ Error: {e}")
    import traceback
    traceback.print_exc()