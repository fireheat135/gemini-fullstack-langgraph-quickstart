#!/usr/bin/env python3
"""
SEOè¨˜äº‹ä½œæˆ7ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
ãƒªã‚µãƒ¼ãƒâ†’ä¼ç”»â†’åŸ·ç­†â†’ä¿®æ­£â†’å‡ºç¨¿â†’åˆ†æâ†’æ”¹å–„ã®å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Send
from langgraph.graph import StateGraph, START, END
from langchain_core.runnables import RunnableConfig
from langchain_google_genai import ChatGoogleGenerativeAI

from .state import OverallState
from .configuration import Configuration
from .utils import get_research_topic
from .prompts import get_current_date


class WorkflowStep(Enum):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ®µéš"""
    RESEARCH = "research"           # ãƒªã‚µãƒ¼ãƒ
    PLANNING = "planning"           # ä¼ç”»  
    WRITING = "writing"            # åŸ·ç­†
    EDITING = "editing"            # ä¿®æ­£
    PUBLISHING = "publishing"      # å‡ºç¨¿
    ANALYSIS = "analysis"          # åˆ†æ
    IMPROVEMENT = "improvement"    # æ”¹å–„


@dataclass
class SEOWorkflowState:
    """SEOãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹"""
    current_step: WorkflowStep
    topic: str
    target_keywords: List[str] = None
    research_data: Dict[str, Any] = None
    planning_data: Dict[str, Any] = None
    article_content: str = None
    article_metadata: Dict[str, Any] = None
    performance_data: Dict[str, Any] = None
    improvement_suggestions: List[str] = None
    workflow_id: str = None
    created_at: datetime = None
    updated_at: datetime = None


class SEOWorkflowOrchestrator:
    """SEOè¨˜äº‹ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆç®¡ç†"""
    
    def __init__(self, gemini_api_key: str):
        self.gemini_api_key = gemini_api_key
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.7,
            api_key=gemini_api_key
        )
    
    # ============================================================
    # Step 1: ãƒªã‚µãƒ¼ãƒ (Research)
    # ============================================================
    
    def step_1_research(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 1: ãƒªã‚µãƒ¼ãƒæ®µéš
        - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ (Hrefs/ãƒ©ãƒƒã‚³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¢¨)
        - ç«¶åˆè¨˜äº‹åˆ†æ (Deep Researchæ´»ç”¨)
        - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‹ãƒ¼ã‚ºåˆ†æ
        - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        """
        print("ğŸ” Step 1: ãƒªã‚µãƒ¼ãƒé–‹å§‹")
        
        research_prompt = f"""
        ã€Œ{state.topic}ã€ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªSEOãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        
        ä»¥ä¸‹ã®é …ç›®ã‚’èª¿æŸ»ã—ã€JSONå½¢å¼ã§çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
        
        1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
           - ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¨å®š
           - é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰30å€‹ï¼ˆãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«å«ã‚€ï¼‰
           - ç«¶åˆæ€§è©•ä¾¡ï¼ˆEasy/Medium/Hardï¼‰
           - æ¤œç´¢æ„å›³åˆ†é¡ï¼ˆæƒ…å ±åé›†/è³¼è²·/ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        
        2. ç«¶åˆè¨˜äº‹åˆ†æ
           - ä¸Šä½10ã‚µã‚¤ãƒˆã®æƒ³å®šã‚¿ã‚¤ãƒˆãƒ«ãƒ»æ§‹æˆ
           - å¹³å‡æ–‡å­—æ•°
           - å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ
        
        3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‹ãƒ¼ã‚ºåˆ†æ
           - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒšãƒ«ã‚½ãƒŠ3ãƒ‘ã‚¿ãƒ¼ãƒ³
           - å„ãƒšãƒ«ã‚½ãƒŠã®æ¤œç´¢æ„å›³
           - è§£æ±ºã™ã¹ãèª²é¡Œãƒ»æ‚©ã¿
        
        4. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
           - å­£ç¯€æ€§ãƒ»æ™‚æœŸæ€§
           - é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ã®ãƒˆãƒ¬ãƒ³ãƒ‰
           - æ€¥ä¸Šæ˜‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        
        å‡ºåŠ›å½¢å¼ï¼š
        {{
            "keywords": {{
                "main": "{state.topic}",
                "related": ["é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", ...],
                "long_tail": ["ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«1", ...],
                "search_volumes": {{"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": æ¨å®šæœˆé–“æ¤œç´¢æ•°}},
                "competition": {{"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": "Easy/Medium/Hard"}},
                "search_intent": {{"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": "æƒ…å ±åé›†/è³¼è²·/ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³"}}
            }},
            "competitors": [
                {{
                    "title": "æƒ³å®šã‚¿ã‚¤ãƒˆãƒ«",
                    "structure": ["H2è¦‹å‡ºã—1", "H2è¦‹å‡ºã—2", ...],
                    "word_count": æ¨å®šæ–‡å­—æ•°,
                    "strength": "å¼·ã¿",
                    "weakness": "å¼±ã¿"
                }}
            ],
            "user_personas": [
                {{
                    "name": "ãƒšãƒ«ã‚½ãƒŠå",
                    "demographics": "å±æ€§",
                    "search_intent": "æ¤œç´¢æ„å›³",
                    "pain_points": ["èª²é¡Œ1", "èª²é¡Œ2", ...],
                    "goals": ["ç›®æ¨™1", "ç›®æ¨™2", ...]
                }}
            ],
            "trends": {{
                "seasonality": "å­£ç¯€æ€§ã®èª¬æ˜",
                "related_topics": ["é–¢é€£ãƒˆãƒ”ãƒƒã‚¯1", ...],
                "trending_keywords": ["æ€¥ä¸Šæ˜‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", ...]
            }}
        }}
        
        ç¾åœ¨ã®æ—¥ä»˜: {get_current_date()}
        ãƒªã‚µãƒ¼ãƒå¯¾è±¡: {state.topic}
        """
        
        try:
            response = self.llm.invoke(research_prompt)
            research_data = self._parse_json_response(response.content)
            
            state.research_data = research_data
            state.target_keywords = research_data.get("keywords", {}).get("related", [])[:10]
            state.current_step = WorkflowStep.PLANNING
            
            print(f"âœ… ãƒªã‚µãƒ¼ãƒå®Œäº†: {len(state.target_keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹")
            return {"research_data": research_data, "step": "planning"}
            
        except Exception as e:
            print(f"âŒ ãƒªã‚µãƒ¼ãƒã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "research"}
    
    # ============================================================
    # Step 2: ä¼ç”» (Planning)
    # ============================================================
    
    def step_2_planning(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 2: ä¼ç”»æ®µéš
        - 4ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨˜äº‹ä¼ç”»æ¡ˆç”Ÿæˆ
        - ãƒˆãƒ³ãƒãƒŠè¨­è¨ˆ
        - è¨˜äº‹æ§‹æˆè¨­è¨ˆ
        - æˆæœäºˆæ¸¬
        """
        print("ğŸ“‹ Step 2: ä¼ç”»é–‹å§‹")
        
        planning_prompt = f"""
        ãƒªã‚µãƒ¼ãƒçµæœã‚’åŸºã«ã€ã€Œ{state.topic}ã€ã®è¨˜äº‹ä¼ç”»ã‚’4ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿:
        {state.research_data}
        
        ä»¥ä¸‹ã®4ã¤ã®ä¼ç”»ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¨˜äº‹æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
        
        1. åˆå¿ƒè€…å‘ã‘è§£èª¬å‹
        2. å°‚é–€å®¶å‘ã‘è©³ç´°å‹  
        3. å®Ÿè·µãƒ»How-toå‹
        4. æ¯”è¼ƒãƒ»ã¾ã¨ã‚å‹
        
        å„ä¼ç”»æ¡ˆã«ã¤ã„ã¦ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
        
        - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒšãƒ«ã‚½ãƒŠ
        - è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆH1ï¼‰
        - ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
        - è¨˜äº‹æ§‹æˆï¼ˆH2-H3ãƒ¬ãƒ™ãƒ«ï¼‰
        - æ¨å®šæ–‡å­—æ•°
        - äºˆæƒ³PVãƒ»CVR
        - å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ï¼ˆæ™‚é–“ãƒ»å°‚é–€æ€§ï¼‰
        - ãƒˆãƒ³ãƒãƒŠè¨­å®š
        - å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ
        
        å‡ºåŠ›å½¢å¼ï¼š
        {{
            "planning_patterns": [
                {{
                    "type": "åˆå¿ƒè€…å‘ã‘è§£èª¬å‹",
                    "target_persona": "ãƒšãƒ«ã‚½ãƒŠèª¬æ˜",
                    "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
                    "meta_description": "ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³",
                    "structure": [
                        {{
                            "h2": "å¤§è¦‹å‡ºã—",
                            "h3_items": ["å°è¦‹å‡ºã—1", "å°è¦‹å‡ºã—2", ...]
                        }}
                    ],
                    "estimated_word_count": æ•°å€¤,
                    "expected_pv": æ•°å€¤,
                    "expected_cvr": æ•°å€¤,
                    "required_time": "æ™‚é–“",
                    "required_expertise": "å¿…è¦å°‚é–€æ€§",
                    "tone_manner": {{
                        "style": "æ–‡ä½“",
                        "voice": "èªèª¿", 
                        "personality": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼"
                    }},
                    "differentiation": ["å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ1", ...]
                }}
            ],
            "recommendation": {{
                "best_pattern": "æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³",
                "reason": "æ¨å¥¨ç†ç”±",
                "success_probability": æ•°å€¤
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(planning_prompt)
            planning_data = self._parse_json_response(response.content)
            
            state.planning_data = planning_data
            state.current_step = WorkflowStep.WRITING
            
            patterns_count = len(planning_data.get("planning_patterns", []))
            print(f"âœ… ä¼ç”»å®Œäº†: {patterns_count}ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ")
            return {"planning_data": planning_data, "step": "writing"}
            
        except Exception as e:
            print(f"âŒ ä¼ç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "planning"}
    
    # ============================================================
    # Step 3: åŸ·ç­† (Writing)
    # ============================================================
    
    def step_3_writing(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 3: åŸ·ç­†æ®µéš
        - æ¨å¥¨ä¼ç”»æ¡ˆã®è¨˜äº‹åŸ·ç­†
        - SEOæœ€é©åŒ–
        - ãƒ¡ã‚¿æƒ…å ±ç”Ÿæˆ
        - ã‚µãƒ ãƒã‚¤ãƒ«ç”ŸæˆæŒ‡ç¤º
        """
        print("âœï¸ Step 3: åŸ·ç­†é–‹å§‹")
        
        # æ¨å¥¨ä¼ç”»æ¡ˆã‚’é¸æŠ
        recommended_pattern = None
        if state.planning_data and "recommendation" in state.planning_data:
            best_pattern_name = state.planning_data["recommendation"]["best_pattern"]
            for pattern in state.planning_data.get("planning_patterns", []):
                if pattern["type"] == best_pattern_name:
                    recommended_pattern = pattern
                    break
        
        if not recommended_pattern:
            return {"error": "æ¨å¥¨ä¼ç”»æ¡ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "step": "planning"}
        
        writing_prompt = f"""
        ä»¥ä¸‹ã®ä¼ç”»æ¡ˆã«åŸºã¥ã„ã¦ã€å®Œå…¨ãªSEOè¨˜äº‹ã‚’åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚
        
        ä¼ç”»æ¡ˆ:
        {recommended_pattern}
        
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±:
        {state.target_keywords}
        
        åŸ·ç­†è¦ä»¶:
        1. æŒ‡å®šã•ã‚ŒãŸæ§‹æˆã«å¾“ã£ã¦è©³ç´°ãªè¨˜äº‹ã‚’ä½œæˆ
        2. è‡ªç„¶ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é…ç½®ã§SEOåŠ¹æœã‚’æœ€å¤§åŒ–
        3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢æ„å›³ã‚’å®Œå…¨ã«æº€ãŸã™å†…å®¹
        4. å°‚é–€æ€§ãƒ»æ¨©å¨æ€§ãƒ»ä¿¡é ¼æ€§(E-A-T)ã‚’é‡è¦–
        5. èª­ã¿ã‚„ã™ãé­…åŠ›çš„ãªæ–‡ç« 
        6. ç›®æ¨™æ–‡å­—æ•°: {recommended_pattern.get('estimated_word_count', 4000)}æ–‡å­—
        
        å‡ºåŠ›å½¢å¼ï¼š
        {{
            "article": {{
                "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
                "meta_description": "ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³", 
                "content": "Markdownå½¢å¼ã®è¨˜äº‹æœ¬æ–‡",
                "word_count": å®Ÿéš›ã®æ–‡å­—æ•°,
                "keywords_used": ["ä½¿ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", ...],
                "internal_links": ["å†…éƒ¨ãƒªãƒ³ã‚¯å€™è£œ1", ...],
                "external_links": ["å¤–éƒ¨ãƒªãƒ³ã‚¯å€™è£œ1", ...]
            }},
            "seo_optimization": {{
                "title_seo_score": æ•°å€¤,
                "keyword_density": æ•°å€¤,
                "readability_score": æ•°å€¤,
                "meta_optimized": true/false
            }},
            "thumbnail_prompt": "ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            "social_media": {{
                "twitter_summary": "Twitterç”¨è¦ç´„",
                "facebook_description": "Facebookç”¨èª¬æ˜",
                "linkedin_summary": "LinkedInç”¨è¦ç´„"
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(writing_prompt)
            writing_data = self._parse_json_response(response.content)
            
            state.article_content = writing_data.get("article", {}).get("content", "")
            state.article_metadata = {
                "title": writing_data.get("article", {}).get("title", ""),
                "meta_description": writing_data.get("article", {}).get("meta_description", ""),
                "word_count": writing_data.get("article", {}).get("word_count", 0),
                "seo_score": writing_data.get("seo_optimization", {}),
                "thumbnail_prompt": writing_data.get("thumbnail_prompt", ""),
                "social_media": writing_data.get("social_media", {})
            }
            state.current_step = WorkflowStep.EDITING
            
            word_count = state.article_metadata.get("word_count", 0)
            print(f"âœ… åŸ·ç­†å®Œäº†: {word_count:,}æ–‡å­—ã®è¨˜äº‹ç”Ÿæˆ")
            return {"article_data": writing_data, "step": "editing"}
            
        except Exception as e:
            print(f"âŒ åŸ·ç­†ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "writing"}
    
    # ============================================================
    # Step 4: ä¿®æ­£ (Editing) 
    # ============================================================
    
    def step_4_editing(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 4: ä¿®æ­£æ®µéš
        - AIã«ã‚ˆã‚‹è¨˜äº‹å“è³ªãƒã‚§ãƒƒã‚¯
        - SEOæœ€é©åŒ–ææ¡ˆ
        - æ”¹å–„æ¡ˆç”Ÿæˆ
        - Notioné¢¨ç·¨é›†å€™è£œç”Ÿæˆ
        """
        print("ğŸ”§ Step 4: ä¿®æ­£ãƒ»ç·¨é›†é–‹å§‹")
        
        editing_prompt = f"""
        ä½œæˆã•ã‚ŒãŸè¨˜äº‹ã‚’è©³ç´°ã«åˆ†æã—ã€æ”¹å–„ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        
        è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {state.article_metadata.get('title', '')}
        è¨˜äº‹å†…å®¹: {state.article_content[:2000]}...
        
        ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æãƒ»æ”¹å–„ææ¡ˆã—ã¦ãã ã•ã„ï¼š
        
        1. SEOæœ€é©åŒ–
           - ã‚¿ã‚¤ãƒˆãƒ«ã®æ”¹å–„æ¡ˆ
           - ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã®æ”¹å–„æ¡ˆ  
           - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é…ç½®ã®æœ€é©åŒ–
           - è¦‹å‡ºã—æ§‹æˆã®æ”¹å–„
        
        2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ª
           - æƒ…å ±ã®æ­£ç¢ºæ€§ãƒ»ç¶²ç¾…æ€§
           - è«–ç†æ§‹æˆã®æ”¹å–„
           - èª­ã¿ã‚„ã™ã•ã®å‘ä¸Š
           - E-A-Tå¼·åŒ–æ¡ˆ
        
        3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹
           - å°å…¥éƒ¨ã®é­…åŠ›å‘ä¸Š
           - ä¸­é–“éƒ¨ã® engagementç¶­æŒ
           - çµè«–éƒ¨ã® actionä¿ƒé€²
           - è¦–è¦šçš„è¦ç´ ã®ææ¡ˆ
        
        4. Notioné¢¨ç·¨é›†ã‚³ãƒãƒ³ãƒ‰
           - å…·ä½“çš„ãªç·¨é›†æŒ‡ç¤º
           - ç½®æ›ã™ã¹ãæ–‡ç« ã¨æ”¹å–„æ¡ˆ
           - è¿½åŠ ã™ã¹ãæƒ…å ±
           - å‰Šé™¤ã™ã¹ãç®‡æ‰€
        
        å‡ºåŠ›å½¢å¼:
        {{
            "seo_improvements": {{
                "title_suggestions": ["æ”¹å–„ã‚¿ã‚¤ãƒˆãƒ«æ¡ˆ1", ...],
                "meta_suggestions": ["æ”¹å–„ãƒ¡ã‚¿æ¡ˆ1", ...], 
                "keyword_optimization": ["æœ€é©åŒ–ææ¡ˆ1", ...],
                "structure_improvements": ["æ§‹æˆæ”¹å–„æ¡ˆ1", ...]
            }},
            "content_improvements": {{
                "accuracy_fixes": ["æ­£ç¢ºæ€§æ”¹å–„1", ...],
                "logic_improvements": ["è«–ç†æ”¹å–„1", ...],
                "readability_fixes": ["èª­ã¿ã‚„ã™ã•æ”¹å–„1", ...],
                "eat_enhancements": ["E-A-Tå¼·åŒ–æ¡ˆ1", ...]
            }},
            "ux_improvements": {{
                "intro_enhancements": ["å°å…¥æ”¹å–„1", ...],
                "engagement_tips": ["engagementæ”¹å–„1", ...],
                "cta_improvements": ["CTAæ”¹å–„1", ...],
                "visual_suggestions": ["è¦–è¦šçš„æ”¹å–„1", ...]
            }},
            "editing_commands": [
                {{
                    "type": "replace",
                    "target": "ç½®æ›å¯¾è±¡æ–‡ç« ",
                    "replacement": "æ”¹å–„æ–‡ç« ", 
                    "reason": "æ”¹å–„ç†ç”±"
                }},
                {{
                    "type": "add",
                    "position": "è¿½åŠ ä½ç½®",
                    "content": "è¿½åŠ å†…å®¹",
                    "reason": "è¿½åŠ ç†ç”±"
                }},
                {{
                    "type": "delete", 
                    "target": "å‰Šé™¤å¯¾è±¡",
                    "reason": "å‰Šé™¤ç†ç”±"
                }}
            ],
            "overall_score": {{
                "seo_score": æ•°å€¤,
                "content_score": æ•°å€¤,
                "ux_score": æ•°å€¤,
                "overall_score": æ•°å€¤
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(editing_prompt)
            editing_data = self._parse_json_response(response.content)
            
            state.current_step = WorkflowStep.PUBLISHING
            
            commands_count = len(editing_data.get("editing_commands", []))
            overall_score = editing_data.get("overall_score", {}).get("overall_score", 0)
            print(f"âœ… ç·¨é›†åˆ†æå®Œäº†: {commands_count}å€‹ã®æ”¹å–„ææ¡ˆ (ã‚¹ã‚³ã‚¢: {overall_score})")
            return {"editing_data": editing_data, "step": "publishing"}
            
        except Exception as e:
            print(f"âŒ ç·¨é›†ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "editing"}
    
    # ============================================================
    # Step 5: å‡ºç¨¿ (Publishing)
    # ============================================================
    
    def step_5_publishing(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 5: å‡ºç¨¿æ®µéš
        - å…¬é–‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–
        - CMSé€£æºæº–å‚™
        - SNSæŠ•ç¨¿æº–å‚™
        - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡è¨­å®š
        """
        print("ğŸ“¤ Step 5: å‡ºç¨¿æº–å‚™é–‹å§‹")
        
        publishing_prompt = f"""
        è¨˜äº‹ã®å‡ºç¨¿æˆ¦ç•¥ã‚’ç­–å®šã—ã¦ãã ã•ã„ã€‚
        
        è¨˜äº‹æƒ…å ±:
        - ã‚¿ã‚¤ãƒˆãƒ«: {state.article_metadata.get('title', '')}
        - æ–‡å­—æ•°: {state.article_metadata.get('word_count', 0)}
        - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {state.target_keywords[:5]}
        
        ä»¥ä¸‹ã®å‡ºç¨¿æˆ¦ç•¥ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ï¼š
        
        1. å…¬é–‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°æœ€é©åŒ–
           - æœ€é©ãªå…¬é–‹æ—¥æ™‚
           - æ›œæ—¥ãƒ»æ™‚é–“å¸¯ã®æ ¹æ‹ 
           - å­£ç¯€æ€§ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è€ƒæ…®
        
        2. CMSè¨­å®š
           - ã‚«ãƒ†ã‚´ãƒªãƒ»ã‚¿ã‚°è¨­å®š
           - URLæ§‹é€ ææ¡ˆ
           - å†…éƒ¨ãƒªãƒ³ã‚¯æˆ¦ç•¥
           - é–¢é€£è¨˜äº‹è¨­å®š
        
        3. SNSæˆ¦ç•¥
           - TwitteræŠ•ç¨¿æ–‡æ¡ˆ
           - FacebookæŠ•ç¨¿æ–‡æ¡ˆ
           - LinkedInæŠ•ç¨¿æ–‡æ¡ˆ
           - InstagramæŠ•ç¨¿ã‚¢ã‚¤ãƒ‡ã‚¢
        
        4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
           - è¿½è·¡ã™ã¹ãKPI
           - åˆ†ææœŸé–“è¨­å®š
           - æ¯”è¼ƒå¯¾è±¡è¨˜äº‹
           - æˆåŠŸæŒ‡æ¨™å®šç¾©
        
        å‡ºåŠ›å½¢å¼:
        {{
            "publishing_schedule": {{
                "optimal_datetime": "YYYY-MM-DD HH:MM",
                "dayofweek_reason": "æ›œæ—¥é¸æŠç†ç”±",
                "time_reason": "æ™‚é–“é¸æŠç†ç”±",
                "seasonal_consideration": "å­£ç¯€æ€§è€ƒæ…®"
            }},
            "cms_settings": {{
                "categories": ["ã‚«ãƒ†ã‚´ãƒª1", ...],
                "tags": ["ã‚¿ã‚°1", ...],
                "url_slug": "url-slug",
                "internal_links": ["å†…éƒ¨ãƒªãƒ³ã‚¯URL1", ...],
                "related_articles": ["é–¢é€£è¨˜äº‹1", ...]
            }},
            "social_media_strategy": {{
                "twitter": {{
                    "posts": ["æŠ•ç¨¿æ–‡1", "æŠ•ç¨¿æ–‡2", ...],
                    "hashtags": ["#ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1", ...],
                    "timing": ["æŠ•ç¨¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°1", ...]
                }},
                "facebook": {{
                    "post": "FacebookæŠ•ç¨¿æ–‡",
                    "image_suggestion": "ç”»åƒææ¡ˆ"
                }},
                "linkedin": {{
                    "post": "LinkedInæŠ•ç¨¿æ–‡", 
                    "professional_angle": "å°‚é–€æ€§ã‚¢ãƒ”ãƒ¼ãƒ«"
                }}
            }},
            "performance_tracking": {{
                "kpis": ["KPI1", "KPI2", ...],
                "tracking_period": "è¿½è·¡æœŸé–“",
                "comparison_articles": ["æ¯”è¼ƒè¨˜äº‹1", ...],
                "success_criteria": {{
                    "pv_target": æ•°å€¤,
                    "engagement_target": æ•°å€¤,
                    "conversion_target": æ•°å€¤
                }}
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(publishing_prompt)
            publishing_data = self._parse_json_response(response.content)
            
            state.current_step = WorkflowStep.ANALYSIS
            
            optimal_time = publishing_data.get("publishing_schedule", {}).get("optimal_datetime", "")
            print(f"âœ… å‡ºç¨¿æˆ¦ç•¥å®Œäº†: æœ€é©å…¬é–‹æ™‚åˆ» {optimal_time}")
            return {"publishing_data": publishing_data, "step": "analysis"}
            
        except Exception as e:
            print(f"âŒ å‡ºç¨¿æˆ¦ç•¥ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "publishing"}
    
    # ============================================================
    # Step 6: åˆ†æ (Analysis)
    # ============================================================
    
    def step_6_analysis(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 6: åˆ†ææ®µéš
        - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
        - ã‚¿ã‚®ãƒ³ã‚°æˆ¦ç•¥
        - åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯è¨­å®š
        - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨­å®š
        """
        print("ğŸ“Š Step 6: åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯è¨­å®šé–‹å§‹")
        
        analysis_prompt = f"""
        è¨˜äº‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
        
        è¨˜äº‹æƒ…å ±:
        - ã‚¿ã‚¤ãƒˆãƒ«: {state.article_metadata.get('title', '')}
        - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {state.target_keywords}
        - æ¨å®šæ–‡å­—æ•°: {state.article_metadata.get('word_count', 0)}
        
        ä»¥ä¸‹ã®åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ï¼š
        
        1. è¨˜äº‹ã‚¿ã‚®ãƒ³ã‚°æˆ¦ç•¥
           - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ç”¨ã‚¿ã‚°
           - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç‰¹æ€§ã‚¿ã‚°  
           - SEOå±æ€§ã‚¿ã‚°
           - å®Ÿé¨“å¤‰æ•°ã‚¿ã‚°
        
        2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
           - PVäºˆæ¸¬ï¼ˆ1é€±é–“ã€1ãƒ¶æœˆã€3ãƒ¶æœˆï¼‰
           - æ¤œç´¢é †ä½äºˆæ¸¬
           - ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬
           - ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³äºˆæ¸¬
        
        3. çµ±è¨ˆåˆ†æè¨­è¨ˆ
           - A/Bãƒ†ã‚¹ãƒˆè¨­è¨ˆ
           - å› æœæ¨è«–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
           - æ¯”è¼ƒå¯¾ç…§ç¾¤è¨­å®š
           - äº¤çµ¡è¦å› ã®ç‰¹å®š
        
        4. æˆåŠŸæŒ‡æ¨™ãƒ»KPI
           - çŸ­æœŸæŒ‡æ¨™ï¼ˆ1-4é€±é–“ï¼‰
           - ä¸­æœŸæŒ‡æ¨™ï¼ˆ1-3ãƒ¶æœˆï¼‰
           - é•·æœŸæŒ‡æ¨™ï¼ˆ3-12ãƒ¶æœˆï¼‰
           - ç›¸å¯¾æŒ‡æ¨™ãƒ»çµ¶å¯¾æŒ‡æ¨™
        
        å‡ºåŠ›å½¢å¼:
        {{
            "article_tags": {{
                "performance_tags": ["tag1", "tag2", ...],
                "content_tags": ["content_tag1", ...],
                "seo_tags": ["seo_tag1", ...],
                "experiment_tags": ["exp_tag1", ...]
            }},
            "performance_predictions": {{
                "pv_predictions": {{
                    "week_1": æ•°å€¤,
                    "month_1": æ•°å€¤,
                    "month_3": æ•°å€¤
                }},
                "ranking_predictions": {{
                    "main_keyword": æ•°å€¤,
                    "related_keywords": {{"keyword": äºˆæ¸¬é †ä½}}
                }},
                "engagement_predictions": {{
                    "bounce_rate": æ•°å€¤,
                    "time_on_page": æ•°å€¤,
                    "social_shares": æ•°å€¤
                }},
                "conversion_predictions": {{
                    "email_signups": æ•°å€¤,
                    "contact_forms": æ•°å€¤,
                    "sales": æ•°å€¤
                }}
            }},
            "statistical_analysis": {{
                "ab_test_design": {{
                    "test_variables": ["å¤‰æ•°1", ...],
                    "control_group": "å¯¾ç…§ç¾¤è¨­å®š",
                    "sample_size": æ•°å€¤,
                    "test_duration": "æœŸé–“"
                }},
                "causal_inference": {{
                    "method": "æ‰‹æ³•å",
                    "control_variables": ["çµ±åˆ¶å¤‰æ•°1", ...],
                    "confounding_factors": ["äº¤çµ¡è¦å› 1", ...]
                }},
                "comparison_framework": {{
                    "similar_articles": ["é¡ä¼¼è¨˜äº‹1", ...],
                    "benchmark_metrics": ["ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡æ¨™1", ...],
                    "comparison_period": "æ¯”è¼ƒæœŸé–“"
                }}
            }},
            "success_metrics": {{
                "short_term": {{
                    "metrics": ["æŒ‡æ¨™1", ...],
                    "targets": {{"æŒ‡æ¨™1": ç›®æ¨™å€¤}},
                    "period": "1-4 weeks"
                }},
                "medium_term": {{
                    "metrics": ["æŒ‡æ¨™1", ...],
                    "targets": {{"æŒ‡æ¨™1": ç›®æ¨™å€¤}},
                    "period": "1-3 months"  
                }},
                "long_term": {{
                    "metrics": ["æŒ‡æ¨™1", ...],
                    "targets": {{"æŒ‡æ¨™1": ç›®æ¨™å€¤}},
                    "period": "3-12 months"
                }}
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(analysis_prompt)
            analysis_data = self._parse_json_response(response.content)
            
            state.performance_data = analysis_data
            state.current_step = WorkflowStep.IMPROVEMENT
            
            predictions = analysis_data.get("performance_predictions", {})
            month1_pv = predictions.get("pv_predictions", {}).get("month_1", 0)
            print(f"âœ… åˆ†æè¨­è¨ˆå®Œäº†: 1ãƒ¶æœˆPVäºˆæ¸¬ {month1_pv:,}")
            return {"analysis_data": analysis_data, "step": "improvement"}
            
        except Exception as e:
            print(f"âŒ åˆ†æè¨­è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "analysis"}
    
    # ============================================================
    # Step 7: æ”¹å–„ (Improvement)
    # ============================================================
    
    def step_7_improvement(self, state: SEOWorkflowState, config: RunnableConfig) -> Dict[str, Any]:
        """
        Step 7: æ”¹å–„æ®µéš
        - ç¶™ç¶šçš„æ”¹å–„è¨ˆç”»
        - å­¦ç¿’ãƒ«ãƒ¼ãƒ—è¨­è¨ˆ
        - æ¬¡å›è¨˜äº‹ã¸ã®æè¨€
        - å…¨ä½“æœ€é©åŒ–æˆ¦ç•¥
        """
        print("ğŸ”„ Step 7: æ”¹å–„ãƒ»æœ€é©åŒ–è¨ˆç”»ç­–å®šé–‹å§‹")
        
        improvement_prompt = f"""
        è¨˜äº‹ä½œæˆãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚Šã€ç¶™ç¶šçš„æ”¹å–„è¨ˆç”»ã‚’ç­–å®šã—ã¦ãã ã•ã„ã€‚
        
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœ:
        - ãƒªã‚µãƒ¼ãƒçµæœ: {state.research_data}
        - ä¼ç”»çµæœ: {state.planning_data}  
        - è¨˜äº‹å“è³ª: {state.article_metadata}
        - åˆ†æè¨­è¨ˆ: {state.performance_data}
        
        ä»¥ä¸‹ã®æ”¹å–„è¨ˆç”»ã‚’ç­–å®šã—ã¦ãã ã•ã„ï¼š
        
        1. ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„
           - å„ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€é©åŒ–æ¡ˆ
           - åŠ¹ç‡åŒ–ãƒ»è‡ªå‹•åŒ–ææ¡ˆ
           - å“è³ªå‘ä¸Šæ–½ç­–
           - ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–
        
        2. å­¦ç¿’ãƒ«ãƒ¼ãƒ—è¨­è¨ˆ
           - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ´»ç”¨
           - å¤±æ•—ãƒ»æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
           - A/Bãƒ†ã‚¹ãƒˆçµæœåæ˜ 
           - ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æ›´æ–°
        
        3. æ¬¡å›è¨˜äº‹ã¸ã®æè¨€
           - ãƒˆãƒ”ãƒƒã‚¯é¸å®šæ”¹å–„
           - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æˆ¦ç•¥èª¿æ•´
           - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªå‘ä¸Š
           - ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        
        4. å…¨ä½“æˆ¦ç•¥æœ€é©åŒ–
           - ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–
           - ãƒªã‚½ãƒ¼ã‚¹é…åˆ†èª¿æ•´
           - ROIæœ€å¤§åŒ–æˆ¦ç•¥
           - é•·æœŸæˆé•·è¨ˆç”»
        
        å‡ºåŠ›å½¢å¼:
        {{
            "process_improvements": {{
                "research_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "planning_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "writing_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "editing_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "publishing_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "analysis_optimization": ["æ”¹å–„æ¡ˆ1", ...],
                "automation_opportunities": ["è‡ªå‹•åŒ–æ¡ˆ1", ...]
            }},
            "learning_loop": {{
                "feedback_mechanisms": ["ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ‰‹æ³•1", ...],
                "pattern_recognition": ["ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜æ‰‹æ³•1", ...],
                "ab_test_integration": ["A/Bãƒ†ã‚¹ãƒˆçµ±åˆæ–¹æ³•1", ...],
                "best_practice_updates": ["ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æ›´æ–°æ–¹æ³•1", ...]
            }},
            "next_article_recommendations": {{
                "topic_selection": ["ãƒˆãƒ”ãƒƒã‚¯é¸å®šæ”¹å–„1", ...],
                "keyword_strategy": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æˆ¦ç•¥æ”¹å–„1", ...],
                "content_quality": ["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªæ”¹å–„1", ...],
                "promotion_strategy": ["ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æ”¹å–„1", ...]
            }},
            "strategic_optimization": {{
                "portfolio_optimization": ["ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–1", ...],
                "resource_allocation": ["ãƒªã‚½ãƒ¼ã‚¹é…åˆ†æœ€é©åŒ–1", ...],
                "roi_maximization": ["ROIæœ€å¤§åŒ–æˆ¦ç•¥1", ...],
                "growth_strategy": ["æˆé•·æˆ¦ç•¥1", ...],
                "competitive_advantage": ["ç«¶äº‰å„ªä½æˆ¦ç•¥1", ...]
            }},
            "implementation_plan": {{
                "priority_improvements": ["å„ªå…ˆæ”¹å–„é …ç›®1", ...],
                "timeline": {{"æ”¹å–„é …ç›®1": "å®Ÿè£…æœŸé–“"}},
                "resources_needed": {{"æ”¹å–„é …ç›®1": "å¿…è¦ãƒªã‚½ãƒ¼ã‚¹"}},
                "success_metrics": {{"æ”¹å–„é …ç›®1": "æˆåŠŸæŒ‡æ¨™"}}
            }}
        }}
        """
        
        try:
            response = self.llm.invoke(improvement_prompt)
            improvement_data = self._parse_json_response(response.content)
            
            state.improvement_suggestions = improvement_data.get("priority_improvements", [])
            state.updated_at = datetime.now()
            
            priority_count = len(state.improvement_suggestions)
            print(f"âœ… æ”¹å–„è¨ˆç”»å®Œäº†: {priority_count}å€‹ã®å„ªå…ˆæ”¹å–„é …ç›®")
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†
            return {
                "improvement_data": improvement_data,
                "workflow_complete": True,
                "final_state": state
            }
            
        except Exception as e:
            print(f"âŒ æ”¹å–„è¨ˆç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "step": "improvement"}
    
    # ============================================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰
    # ============================================================
    
    def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
        """JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹"""
        import json
        
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            if end != -1:
                json_text = response_text[start:end].strip()
            else:
                json_text = response_text[start:].strip()
        else:
            json_text = response_text.strip()
        
        try:
            return json.loads(json_text)
        except json.JSONDecodeError as e:
            print(f"JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ: {json_text[:500]}...")
            return {}
    
    def execute_full_workflow(self, topic: str) -> SEOWorkflowState:
        """å®Œå…¨ãªSEOãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ"""
        print(f"ğŸš€ SEOè¨˜äº‹ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹: {topic}")
        print("=" * 60)
        
        # åˆæœŸçŠ¶æ…‹ä½œæˆ
        state = SEOWorkflowState(
            current_step=WorkflowStep.RESEARCH,
            topic=topic,
            workflow_id=f"seo_{int(datetime.now().timestamp())}",
            created_at=datetime.now()
        )
        
        config = RunnableConfig()
        
        # 7ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œ
        steps = [
            ("Step 1: ãƒªã‚µãƒ¼ãƒ", self.step_1_research),
            ("Step 2: ä¼ç”»", self.step_2_planning),
            ("Step 3: åŸ·ç­†", self.step_3_writing),
            ("Step 4: ä¿®æ­£", self.step_4_editing),
            ("Step 5: å‡ºç¨¿", self.step_5_publishing),
            ("Step 6: åˆ†æ", self.step_6_analysis),
            ("Step 7: æ”¹å–„", self.step_7_improvement)
        ]
        
        results = {}
        
        for step_name, step_func in steps:
            print(f"\n{step_name}")
            print("-" * 40)
            
            try:
                result = step_func(state, config)
                results[step_name] = result
                
                if "error" in result:
                    print(f"âŒ {step_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result['error']}")
                    break
                    
            except Exception as e:
                print(f"âŒ {step_name} ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                break
        
        print("\n" + "=" * 60)
        print("ğŸ‰ SEOè¨˜äº‹ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†")
        print(f"æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—: {state.current_step.value}")
        print(f"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {state.article_metadata.get('title', 'N/A') if state.article_metadata else 'N/A'}")
        print(f"æ–‡å­—æ•°: {state.article_metadata.get('word_count', 0) if state.article_metadata else 0:,}")
        print(f"æ”¹å–„ææ¡ˆæ•°: {len(state.improvement_suggestions) if state.improvement_suggestions else 0}")
        
        return state


# ============================================================
# LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆ
# ============================================================

def create_seo_workflow_graph(gemini_api_key: str) -> StateGraph:
    """SEOè¨˜äº‹ä½œæˆLangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ"""
    
    orchestrator = SEOWorkflowOrchestrator(gemini_api_key)
    
    def research_node(state: OverallState, config: RunnableConfig):
        topic = get_research_topic(state["messages"])
        workflow_state = SEOWorkflowState(
            current_step=WorkflowStep.RESEARCH,
            topic=topic
        )
        result = orchestrator.step_1_research(workflow_state, config)
        return {"research_result": result}
    
    def planning_node(state: OverallState, config: RunnableConfig):
        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœã‚’å–å¾—ã—ã¦ä¼ç”»å®Ÿè¡Œ
        # (å®Ÿè£…è©³ç´°ã¯çœç•¥)
        pass
    
    # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    builder = StateGraph(OverallState, config_schema=Configuration)
    
    # ãƒãƒ¼ãƒ‰è¿½åŠ 
    builder.add_node("seo_research", research_node)
    builder.add_node("seo_planning", planning_node)
    # ä»–ã®ãƒãƒ¼ãƒ‰ã‚‚åŒæ§˜ã«è¿½åŠ ...
    
    # ã‚¨ãƒƒã‚¸è¿½åŠ 
    builder.add_edge(START, "seo_research")
    builder.add_edge("seo_research", "seo_planning")
    # ä»–ã®ã‚¨ãƒƒã‚¸ã‚‚åŒæ§˜ã«è¿½åŠ ...
    
    return builder.compile(name="seo-workflow-graph")


# ============================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
# ============================================================

if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        exit(1)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    orchestrator = SEOWorkflowOrchestrator(gemini_api_key)
    final_state = orchestrator.execute_full_workflow("èª•ç”ŸèŠ±")
    
    print(f"\nğŸ“‹ æœ€çµ‚çµæœ:")
    print(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ID: {final_state.workflow_id}")
    print(f"ãƒˆãƒ”ãƒƒã‚¯: {final_state.topic}")
    print(f"æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—: {final_state.current_step.value}")
    print(f"å‡¦ç†æ™‚é–“: {final_state.updated_at - final_state.created_at if final_state.updated_at else 'N/A'}")