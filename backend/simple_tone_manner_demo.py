"""
Simple Tone & Manner Engine Demo
ãƒˆãƒ³ãƒãƒŠä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®ã‚·ãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¢ï¼ˆä¾å­˜é–¢ä¿‚ãªã—ï¼‰
"""

import re
import statistics
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import List, Dict, Any, Optional
from collections import Counter


class ToneType(Enum):
    FRIENDLY = "è¦ªã—ã¿ã‚„ã™ã„"
    FORMAL = "ãƒ•ã‚©ãƒ¼ãƒãƒ«"
    CASUAL = "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"


class FormalityLevel(Enum):
    CASUAL = "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"
    POLITE = "ä¸å¯§" 
    VERY_FORMAL = "ã¨ã¦ã‚‚ãƒ•ã‚©ãƒ¼ãƒãƒ«"


class WritingStyle(Enum):
    INFORMATIVE = "æƒ…å ±æä¾›å‹"
    ACADEMIC = "å­¦è¡“çš„"


class InconsistencyType(Enum):
    TONE_MISMATCH = "tone_mismatch"
    FORMALITY_MISMATCH = "formality_mismatch"
    WRITING_STYLE_MISMATCH = "writing_style_mismatch"


@dataclass
class ToneManner:
    tone: str
    formality: str
    target_audience: str
    writing_style: str


@dataclass
class ArticleContent:
    id: str
    title: str
    content: str
    keyword: str
    tone_manner: ToneManner
    created_at: datetime


@dataclass
class BrandVoiceProfile:
    brand_name: str
    preferred_tone: ToneType
    preferred_formality: FormalityLevel
    preferred_writing_style: WritingStyle
    target_audience: str
    brand_keywords: List[str]
    avoid_keywords: List[str]
    voice_characteristics: Dict[str, float]
    style_guidelines: Dict[str, bool]


@dataclass
class ToneInconsistency:
    inconsistency_type: InconsistencyType
    severity: str
    description: str
    location: str
    suggested_fix: str
    confidence_score: float


@dataclass
class ToneMannerAnalysis:
    article_id: str
    consistency_score: float
    target_tone_match: bool
    formality_match: bool
    style_match: bool
    inconsistencies: List[ToneInconsistency]
    brand_voice_compliance: Optional[float] = None


class SimpleToneMannerEngine:
    """Simplified Tone & Manner Engine for demonstration"""
    
    def __init__(self):
        self.historical_articles: List[ArticleContent] = []
        self.brand_voice_profile: Optional[BrandVoiceProfile] = None
    
    def set_brand_voice_profile(self, profile: BrandVoiceProfile):
        """ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š"""
        self.brand_voice_profile = profile
    
    def get_brand_voice_profile(self) -> Optional[BrandVoiceProfile]:
        """ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        return self.brand_voice_profile
    
    def add_historical_article(self, article: ArticleContent):
        """éå»è¨˜äº‹è¿½åŠ """
        self.historical_articles.append(article)
    
    def get_historical_articles_count(self) -> int:
        """éå»è¨˜äº‹æ•°å–å¾—"""
        return len(self.historical_articles)
    
    def analyze_tone_manner(self, article: ArticleContent) -> ToneMannerAnalysis:
        """ãƒˆãƒ³ãƒãƒŠåˆ†æ"""
        if not article.content:
            return ToneMannerAnalysis(
                article_id=article.id,
                consistency_score=0.0,
                target_tone_match=False,
                formality_match=False,
                style_match=False,
                inconsistencies=[],
                brand_voice_compliance=0.0
            )
        
        inconsistencies = []
        
        # éå»è¨˜äº‹ã¨ã®æ¯”è¼ƒ
        if self.historical_articles:
            tone_consistency = self._analyze_tone_consistency(article)
            formality_consistency = self._analyze_formality_consistency(article)  
            style_consistency = self._analyze_style_consistency(article)
            
            # ä¸ä¸€è‡´æ¤œå‡º
            if tone_consistency < 0.7:
                inconsistencies.append(ToneInconsistency(
                    inconsistency_type=InconsistencyType.TONE_MISMATCH,
                    severity="HIGH" if tone_consistency < 0.5 else "MEDIUM",
                    description=f"éå»è¨˜äº‹ã¨ã®ãƒˆãƒ¼ãƒ³ä¸€è‡´åº¦ãŒä½ã„ ({tone_consistency:.2f})",
                    location="å…¨ä½“çš„ãªæ–‡ä½“",
                    suggested_fix="éå»è¨˜äº‹ã®ãƒˆãƒ¼ãƒ³ã«åˆã‚ã›ãŸè¡¨ç¾ã«èª¿æ•´",
                    confidence_score=1.0 - tone_consistency
                ))
            
            if formality_consistency < 0.7:
                inconsistencies.append(ToneInconsistency(
                    inconsistency_type=InconsistencyType.FORMALITY_MISMATCH,
                    severity="HIGH" if formality_consistency < 0.5 else "MEDIUM",
                    description=f"éå»è¨˜äº‹ã¨ã®æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è‡´åº¦ãŒä½ã„ ({formality_consistency:.2f})",
                    location="æ•¬èªè¡¨ç¾",
                    suggested_fix="ä¸€è²«ã—ãŸæ•¬èªãƒ¬ãƒ™ãƒ«ã«èª¿æ•´",
                    confidence_score=1.0 - formality_consistency
                ))
            
            overall_consistency = (tone_consistency + formality_consistency + style_consistency) / 3
        else:
            overall_consistency = 0.8
            tone_consistency = formality_consistency = style_consistency = 0.8
        
        # ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§
        brand_compliance = None
        if self.brand_voice_profile:
            brand_compliance = self._evaluate_brand_voice_compliance(article)
        
        return ToneMannerAnalysis(
            article_id=article.id,
            consistency_score=overall_consistency,
            target_tone_match=tone_consistency >= 0.7,
            formality_match=formality_consistency >= 0.7,
            style_match=style_consistency >= 0.7,
            inconsistencies=inconsistencies,
            brand_voice_compliance=brand_compliance
        )
    
    def evaluate_brand_voice_compliance(self, article: ArticleContent) -> Dict[str, float]:
        """ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡"""
        if not self.brand_voice_profile:
            return {"overall_compliance_score": 0.5, "tone_compliance": 0.5, "formality_compliance": 0.5, "keyword_compliance": 0.5}
        
        tone_compliance = 1.0 if article.tone_manner.tone == self.brand_voice_profile.preferred_tone.value else 0.3
        formality_compliance = 1.0 if article.tone_manner.formality == self.brand_voice_profile.preferred_formality.value else 0.3
        keyword_compliance = self._calculate_keyword_compliance(article.content)
        
        overall_compliance = (tone_compliance + formality_compliance + keyword_compliance) / 3
        
        return {
            "overall_compliance_score": overall_compliance,
            "tone_compliance": tone_compliance,
            "formality_compliance": formality_compliance,
            "keyword_compliance": keyword_compliance
        }
    
    def analyze_brand_keyword_usage(self, content: str) -> Dict[str, Any]:
        """ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨åˆ†æ"""
        if not self.brand_voice_profile:
            return {"used_brand_keywords": [], "avoided_keywords_found": [], "keyword_usage_score": 0.0}
        
        content_lower = content.lower()
        
        used_brand_keywords = [kw for kw in self.brand_voice_profile.brand_keywords if kw.lower() in content_lower]
        avoided_keywords_found = [kw for kw in self.brand_voice_profile.avoid_keywords if kw.lower() in content_lower]
        
        brand_keyword_score = len(used_brand_keywords) / max(len(self.brand_voice_profile.brand_keywords), 1)
        avoid_penalty = len(avoided_keywords_found) * 0.2
        keyword_usage_score = max(0, brand_keyword_score - avoid_penalty)
        
        return {
            "used_brand_keywords": used_brand_keywords,
            "avoided_keywords_found": avoided_keywords_found,
            "keyword_usage_score": keyword_usage_score
        }
    
    def suggest_formality_adjustments(self, text: str) -> List[str]:
        """æ•¬èªèª¿æ•´ææ¡ˆ"""
        suggestions = []
        
        formal_to_casual = {
            "ç”³ã—ä¸Šã’ã¾ã™": "ã—ã¾ã™",
            "ã„ãŸã—ã¾ã™": "ã—ã¾ã™",
            "ã§ã”ã–ã„ã¾ã™": "ã§ã™",
            "ã•ã›ã¦ã„ãŸã ãã¾ã™": "ã—ã¾ã™"
        }
        
        casual_text = text
        for formal, casual in formal_to_casual.items():
            if formal in text:
                casual_text = casual_text.replace(formal, casual)
        
        if casual_text != text:
            suggestions.append(casual_text)
        
        return suggestions
    
    def suggest_expression_modernization(self, text: str) -> List[str]:
        """è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ"""
        suggestions = []
        
        modernization_map = {
            "ã§ã”ã–ã„ã¾ã™": "ã§ã™",
            "ã‹ã‚ˆã†ãª": "ã“ã®ã‚ˆã†ãª",
            "æ‹è¦‹ã„ãŸã—ã¾ã™": "è¦‹ã¾ã™",
            "å­˜ã˜ã¾ã™": "æ€ã„ã¾ã™"
        }
        
        modern_text = text
        for old_expr, modern_expr in modernization_map.items():
            if old_expr in text:
                modern_text = modern_text.replace(old_expr, modern_expr)
        
        if modern_text != text:
            suggestions.append(modern_text)
        
        return suggestions
    
    def analyze_expression_patterns(self) -> Dict[str, Any]:
        """è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        if not self.historical_articles:
            return {"common_expressions": [], "sentence_patterns": [], "emotional_words": []}
        
        all_content = " ".join([article.content for article in self.historical_articles])
        
        # å…±é€šè¡¨ç¾ã®æŠ½å‡º
        common_expressions = []
        expression_patterns = [r'ã§ã™ã­', r'ã¾ã™ã­', r'ã§ã—ã‚‡ã†', r'ã§ã™ã‚ˆ']
        for pattern in expression_patterns:
            if re.search(pattern, all_content):
                common_expressions.append(pattern.replace('\\', ''))
        
        # æ„Ÿæƒ…èªã®æŠ½å‡º
        emotional_words = []
        emotion_keywords = ["ç¾ã—ã„", "ç´ æ™´ã‚‰ã—ã„", "ç™’ã—", "å¿ƒåœ°ã‚ˆã„", "æ¸©ã‹ã„", "å„ªé›…", "å¯æ†", "é­…åŠ›çš„"]
        for word in emotion_keywords:
            if word in all_content:
                emotional_words.append(word)
        
        return {
            "common_expressions": common_expressions,
            "sentence_patterns": [],
            "emotional_words": emotional_words
        }
    
    def analyze_sentence_structure(self, text: str) -> Dict[str, Any]:
        """æ–‡æ§‹é€ åˆ†æ"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return {"sentence_count": 0, "average_sentence_length": 0, "shortest_sentence": 0, "longest_sentence": 0}
        
        sentence_lengths = [len(sentence) for sentence in sentences]
        
        return {
            "sentence_count": len(sentences),
            "average_sentence_length": statistics.mean(sentence_lengths),
            "shortest_sentence": min(sentence_lengths),
            "longest_sentence": max(sentence_lengths)
        }
    
    def track_tone_evolution(self) -> Dict[str, Any]:
        """ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡"""
        if len(self.historical_articles) < 2:
            return {"tone_trends": [], "formality_trends": [], "style_changes": []}
        
        sorted_articles = sorted(self.historical_articles, key=lambda x: x.created_at)
        
        tone_trends = []
        for article in sorted_articles:
            tone_trends.append({
                "date": article.created_at.isoformat(),
                "tone": article.tone_manner.tone,
                "formality": article.tone_manner.formality
            })
        
        style_changes = []
        for i in range(1, len(sorted_articles)):
            prev_style = sorted_articles[i-1].tone_manner.writing_style
            curr_style = sorted_articles[i].tone_manner.writing_style
            
            if prev_style != curr_style:
                style_changes.append({
                    "from_style": prev_style,
                    "to_style": curr_style,
                    "change_date": sorted_articles[i].created_at.isoformat()
                })
        
        return {
            "tone_trends": tone_trends,
            "formality_trends": [],
            "style_changes": style_changes
        }
    
    def _analyze_tone_consistency(self, article: ArticleContent) -> float:
        """ãƒˆãƒ¼ãƒ³ä¸€è²«æ€§åˆ†æ"""
        if not self.historical_articles:
            return 0.8
        
        target_tone = article.tone_manner.tone
        historical_tones = [a.tone_manner.tone for a in self.historical_articles]
        most_common_tone = Counter(historical_tones).most_common(1)[0][0]
        
        return 1.0 if target_tone == most_common_tone else 0.4
    
    def _analyze_formality_consistency(self, article: ArticleContent) -> float:
        """æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è²«æ€§åˆ†æ"""
        if not self.historical_articles:
            return 0.8
        
        target_formality = article.tone_manner.formality
        historical_formalities = [a.tone_manner.formality for a in self.historical_articles]
        most_common_formality = Counter(historical_formalities).most_common(1)[0][0]
        
        return 1.0 if target_formality == most_common_formality else 0.4
    
    def _analyze_style_consistency(self, article: ArticleContent) -> float:
        """æ–‡ä½“ä¸€è²«æ€§åˆ†æ"""
        if not self.historical_articles:
            return 0.8
        
        target_style = article.tone_manner.writing_style
        historical_styles = [a.tone_manner.writing_style for a in self.historical_articles]
        most_common_style = Counter(historical_styles).most_common(1)[0][0]
        
        return 1.0 if target_style == most_common_style else 0.6
    
    def _evaluate_brand_voice_compliance(self, article: ArticleContent) -> float:
        """ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡"""
        compliance_report = self.evaluate_brand_voice_compliance(article)
        return compliance_report["overall_compliance_score"]
    
    def _calculate_keyword_compliance(self, content: str) -> float:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©åˆæ€§è¨ˆç®—"""
        keyword_analysis = self.analyze_brand_keyword_usage(content)
        return keyword_analysis["keyword_usage_score"]


def main():
    """ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¨ Tone & Manner Engine Demo - Phase 5 Implementation")
    print("=" * 60)
    
    # EngineåˆæœŸåŒ–
    tone_engine = SimpleToneMannerEngine()
    print("âœ… Tone & Manner Engine initialized")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    brand_profile = BrandVoiceProfile(
        brand_name="èŠ±ã®å°‚é–€ã‚µã‚¤ãƒˆ",
        preferred_tone=ToneType.FRIENDLY,
        preferred_formality=FormalityLevel.CASUAL,
        preferred_writing_style=WritingStyle.INFORMATIVE,
        target_audience="èŠ±å¥½ãã®å¥³æ€§ï¼ˆ20-50ä»£ï¼‰",
        brand_keywords=["ç¾ã—ã„", "ç™’ã—", "è‡ªç„¶", "å„ªé›…", "å¿ƒåœ°ã‚ˆã„"],
        avoid_keywords=["é›£ã—ã„", "è¤‡é›‘", "å°‚é–€çš„ã™ãã‚‹"],
        voice_characteristics={
            "warmth": 0.8,
            "professionalism": 0.6,
            "friendliness": 0.9,
            "expertise": 0.7,
            "accessibility": 0.8
        },
        style_guidelines={
            "use_honorifics": False,
            "use_casual_expressions": True,
            "include_seasonal_references": True,
            "focus_on_emotions": True
        }
    )
    
    tone_engine.set_brand_voice_profile(brand_profile)
    print("âœ… Brand voice profile configured")
    
    # ä¸€è²«ã—ãŸãƒˆãƒ³ãƒãƒŠã®éå»è¨˜äº‹ã‚’è¿½åŠ 
    consistent_tone = ToneManner(
        tone="è¦ªã—ã¿ã‚„ã™ã„",
        formality="ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«",
        target_audience="èŠ±å¥½ãã®å¥³æ€§",
        writing_style="æƒ…å ±æä¾›å‹"
    )
    
    historical_articles = [
        ArticleContent(
            id="hist_1",
            title="1æœˆã®èª•ç”ŸèŠ±ã€Œã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã€ã§å¿ƒã‚‚æ¸©ã¾ã‚‹å†¬ã®å½©ã‚Š",
            content="å¯’ã„å†¬ã«ã‚‚ç¾ã—ãå’²ãã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€1æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦å¤šãã®äººã«æ„›ã•ã‚Œã¦ã„ã¾ã™ã€‚ãã®æ¸©ã‹ã¿ã®ã‚ã‚‹è‰²åˆã„ã¯ã€è¦‹ã‚‹äººã®å¿ƒã‚’å„ªã—ãåŒ…ã¿è¾¼ã‚“ã§ãã‚Œã¾ã™ã­ã€‚ãŠéƒ¨å±‹ã«é£¾ã‚‹ã¨ã€ä¸€æ°—ã«æ˜ã‚‹ã„é›°å›²æ°—ã«ãªã‚Šã¾ã™ã‚ˆã€‚",
            keyword="1æœˆ èª•ç”ŸèŠ± ã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=30)
        ),
        ArticleContent(
            id="hist_2",
            title="2æœˆã®èª•ç”ŸèŠ±ã€Œãƒ—ãƒªãƒ ãƒ©ã€ãŒé‹ã¶æ˜¥ã®ä¾¿ã‚Š",
            content="å¯æ†ãªãƒ—ãƒªãƒ ãƒ©ã¯ã€2æœˆã®ä»£è¡¨çš„ãªèª•ç”ŸèŠ±ã¨ã—ã¦è¦ªã—ã¾ã‚Œã¦ã„ã¾ã™ã€‚å°ã•ãªèŠ±ã³ã‚‰ãŒé›†ã¾ã£ã¦å’²ãå§¿ã¯ã€ã¾ã‚‹ã§æ˜¥ã®å¦–ç²¾ã®ã‚ˆã†ã§ã™ã­ã€‚è‰²ã¨ã‚Šã©ã‚Šã®èŠ±è‰²ã¯ã€ã¾ã å¯’ã„å­£ç¯€ã«å¿ƒæ¸©ã¾ã‚‹ç™’ã—ã‚’ä¸ãˆã¦ãã‚Œã¾ã™ã€‚",
            keyword="2æœˆ èª•ç”ŸèŠ± ãƒ—ãƒªãƒ ãƒ©",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=20)
        ),
        ArticleContent(
            id="hist_3",
            title="3æœˆã®èª•ç”ŸèŠ±ã€Œæ¡œã€ã§æ„Ÿã˜ã‚‹æ—¥æœ¬ã®ç¾ã—ã•",
            content="æ—¥æœ¬äººã«ã¨ã£ã¦ç‰¹åˆ¥ãªèŠ±ã€æ¡œã€‚3æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦ã‚‚çŸ¥ã‚‰ã‚Œã€ãã®ç¾ã—ã•ã¯å¤šãã®äººã®å¿ƒã‚’é­…äº†ã—ç¶šã‘ã¦ã„ã¾ã™ã€‚æ·¡ã„ãƒ”ãƒ³ã‚¯ã®èŠ±ã³ã‚‰ãŒèˆã„æ•£ã‚‹æ§˜å­ã¯ã€æ—¥æœ¬ãªã‚‰ã§ã¯ã®å„ªé›…ãªç¾æ„è­˜ã‚’æ„Ÿã˜ã•ã›ã¦ãã‚Œã¾ã™ã­ã€‚",
            keyword="3æœˆ èª•ç”ŸèŠ± æ¡œ",
            tone_manner=consistent_tone,
            created_at=datetime.now() - timedelta(days=10)
        )
    ]
    
    print("\nğŸ“š éå»è¨˜äº‹è¿½åŠ ãƒ†ã‚¹ãƒˆ")
    for article in historical_articles:
        tone_engine.add_historical_article(article)
    print(f"   è¿½åŠ å®Œäº†: {tone_engine.get_historical_articles_count()}ä»¶ã®éå»è¨˜äº‹")
    
    # ===== ä¸€è²«ã—ãŸè¨˜äº‹ã®åˆ†æ =====
    print("\nâœ… ä¸€è²«ã—ãŸãƒˆãƒ³ãƒãƒŠè¨˜äº‹ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    consistent_article = ArticleContent(
        id="consistent_test",
        title="4æœˆã®èª•ç”ŸèŠ±ã€Œæ¡œè‰ã€ã®æ„›ã‚‰ã—ã„é­…åŠ›",
        content="æ˜¥ã‚‰ã—ã„æ¡œè‰ã¯ã€4æœˆã®èª•ç”ŸèŠ±ã¨ã—ã¦è¦ªã—ã¾ã‚Œã¦ã„ã¾ã™ã€‚å°ã•ãã¦å¯æ„›ã‚‰ã—ã„èŠ±ã¯ã€è¦‹ã¦ã„ã‚‹ã ã‘ã§å¿ƒãŒç™’ã•ã‚Œã¾ã™ã­ã€‚ã‚¬ãƒ¼ãƒ‡ãƒ‹ãƒ³ã‚°åˆå¿ƒè€…ã®æ–¹ã§ã‚‚è‚²ã¦ã‚„ã™ãã€æ˜¥ã®ãŠåº­ã‚’ç¾ã—ãå½©ã£ã¦ãã‚Œã¾ã™ã‚ˆã€‚",
        keyword="4æœˆ èª•ç”ŸèŠ± æ¡œè‰",
        tone_manner=consistent_tone,
        created_at=datetime.now()
    )
    
    analysis = tone_engine.analyze_tone_manner(consistent_article)
    print(f"   ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {analysis.consistency_score:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³ä¸€è‡´: {analysis.target_tone_match}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è‡´: {analysis.formality_match}")
    print(f"   æ–‡ä½“ä¸€è‡´: {analysis.style_match}")
    print(f"   ä¸ä¸€è‡´ä»¶æ•°: {len(analysis.inconsistencies)}")
    
    # ===== ä¸ä¸€è‡´è¨˜äº‹ã®åˆ†æ =====
    print("\nâš ï¸ ä¸ä¸€è‡´ãƒˆãƒ³ãƒãƒŠè¨˜äº‹ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    inconsistent_article = ArticleContent(
        id="inconsistent_test",
        title="èª•ç”ŸèŠ±ã«é–¢ã™ã‚‹å­¦è¡“çš„è€ƒå¯Ÿ",
        content="èª•ç”ŸèŠ±ã®æ¦‚å¿µã«ã¤ãã¾ã—ã¦ã¯ã€ãã®èµ·æºã‚’19ä¸–ç´€ã®ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã«æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¤ç‰©å­¦çš„è¦³ç‚¹ã‹ã‚‰ç”³ã—ä¸Šã’ã¾ã™ã¨ã€å„æœˆã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸèŠ±å‰ã¯ã€ãã®æ™‚æœŸã®æ°—å€™æ¡ä»¶åŠã³æ ½åŸ¹é©æ€§ã‚’è€ƒæ…®ã—ã¦é¸å®šã•ã‚Œã¦ãŠã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®è¤‡é›‘ã§é›£ã—ã„å°‚é–€çš„è¦å› ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯æ¥µã‚ã¦å›°é›£ã§ã‚ã‚Šã¾ã™ã€‚",
        keyword="èª•ç”ŸèŠ± å­¦è¡“ ç ”ç©¶",
        tone_manner=ToneManner(
            tone="ãƒ•ã‚©ãƒ¼ãƒãƒ«",
            formality="éå¸¸ã«ä¸å¯§",
            target_audience="ç ”ç©¶è€…ãƒ»å°‚é–€å®¶",
            writing_style="å­¦è¡“çš„"
        ),
        created_at=datetime.now()
    )
    
    inconsistent_analysis = tone_engine.analyze_tone_manner(inconsistent_article)
    print(f"   ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {inconsistent_analysis.consistency_score:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³ä¸€è‡´: {inconsistent_analysis.target_tone_match}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«ä¸€è‡´: {inconsistent_analysis.formality_match}")
    print(f"   æ–‡ä½“ä¸€è‡´: {inconsistent_analysis.style_match}")
    print(f"   ä¸ä¸€è‡´ä»¶æ•°: {len(inconsistent_analysis.inconsistencies)}")
    
    # ä¸ä¸€è‡´è©³ç´°ã®è¡¨ç¤º
    print("   æ¤œå‡ºã•ã‚ŒãŸä¸ä¸€è‡´:")
    for inc in inconsistent_analysis.inconsistencies:
        print(f"     - {inc.severity}: {inc.description}")
    
    # ===== ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡ =====
    print("\nğŸ¯ ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡ãƒ†ã‚¹ãƒˆ")
    brand_compliance = tone_engine.evaluate_brand_voice_compliance(consistent_article)
    print(f"   ç·åˆé©åˆåº¦: {brand_compliance['overall_compliance_score']:.3f}")
    print(f"   ãƒˆãƒ¼ãƒ³é©åˆåº¦: {brand_compliance['tone_compliance']:.3f}")
    print(f"   æ•¬èªãƒ¬ãƒ™ãƒ«é©åˆåº¦: {brand_compliance['formality_compliance']:.3f}")
    print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©åˆåº¦: {brand_compliance['keyword_compliance']:.3f}")
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨åˆ†æ
    print("\nğŸ” ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨åˆ†æãƒ†ã‚¹ãƒˆ")
    keyword_usage = tone_engine.analyze_brand_keyword_usage(consistent_article.content)
    print(f"   ä½¿ç”¨ã•ã‚ŒãŸãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword_usage['used_brand_keywords']}")
    print(f"   é¿ã‘ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {keyword_usage['avoided_keywords_found']}")
    print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨ã‚¹ã‚³ã‚¢: {keyword_usage['keyword_usage_score']:.3f}")
    
    # å•é¡Œã®ã‚ã‚‹è¨˜äº‹ã§ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    problematic_keyword_usage = tone_engine.analyze_brand_keyword_usage(inconsistent_article.content)
    print(f"   å•é¡Œè¨˜äº‹ - é¿ã‘ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {problematic_keyword_usage['avoided_keywords_found']}")
    
    # ===== æ•¬èªèª¿æ•´ææ¡ˆ =====
    print("\nğŸ”„ æ•¬èªèª¿æ•´ææ¡ˆãƒ†ã‚¹ãƒˆ")
    formal_text = "ç”³ã—ä¸Šã’ã¾ã™ãŒã€ã“ã®èŠ±ã«ã¤ãã¾ã—ã¦ã¯ã”èª¬æ˜ã•ã›ã¦ã„ãŸã ãã¾ã™"
    formality_suggestions = tone_engine.suggest_formality_adjustments(formal_text)
    print(f"   å…ƒã®æ–‡ç« : {formal_text}")
    print("   èª¿æ•´ææ¡ˆ:")
    for i, suggestion in enumerate(formality_suggestions, 1):
        print(f"     {i}. {suggestion}")
    
    # ===== è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ =====
    print("\nğŸ†• è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆãƒ†ã‚¹ãƒˆ")
    old_text = "ã‹ã‚ˆã†ãªç¾ã—ãèŠ±ã‚’æ‹è¦‹ã„ãŸã—ã¾ã™ã¨ã€å¿ƒãŒæ´—ã‚ã‚Œã‚‹æ€ã„ã§ã”ã–ã„ã¾ã™"
    modern_suggestions = tone_engine.suggest_expression_modernization(old_text)
    print(f"   å…ƒã®æ–‡ç« : {old_text}")
    print("   ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ:")
    for i, suggestion in enumerate(modern_suggestions, 1):
        print(f"     {i}. {suggestion}")
    
    # ===== è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ =====
    print("\nğŸ“Š è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãƒ†ã‚¹ãƒˆ")
    expression_patterns = tone_engine.analyze_expression_patterns()
    print(f"   å…±é€šè¡¨ç¾: {expression_patterns['common_expressions']}")
    print(f"   æ„Ÿæƒ…èª: {expression_patterns['emotional_words']}")
    
    # ===== æ–‡æ§‹é€ åˆ†æ =====
    print("\nğŸ“ æ–‡æ§‹é€ åˆ†æãƒ†ã‚¹ãƒˆ")
    sentence_analysis = tone_engine.analyze_sentence_structure(consistent_article.content)
    print(f"   æ–‡æ•°: {sentence_analysis['sentence_count']}")
    print(f"   å¹³å‡æ–‡é•·: {sentence_analysis['average_sentence_length']:.1f}æ–‡å­—")
    print(f"   æœ€çŸ­æ–‡: {sentence_analysis['shortest_sentence']}æ–‡å­—")
    print(f"   æœ€é•·æ–‡: {sentence_analysis['longest_sentence']}æ–‡å­—")
    
    # ===== ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡ =====
    print("\nğŸ“ˆ ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆ")
    tone_evolution = tone_engine.track_tone_evolution()
    print(f"   ãƒˆãƒ¼ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜éŒ²: {len(tone_evolution['tone_trends'])}ä»¶")
    print(f"   æ–‡ä½“å¤‰åŒ–: {len(tone_evolution['style_changes'])}ä»¶")
    if tone_evolution['tone_trends']:
        latest_trend = tone_evolution['tone_trends'][-1]
        print(f"   æœ€æ–°ã®ãƒˆãƒ¼ãƒ³: {latest_trend['tone']} ({latest_trend['formality']})")
    
    print("\nğŸ‰ Tone & Manner Engine - å…¨æ©Ÿèƒ½å®Ÿè£…å®Œäº†!")
    print("=" * 60)
    print("âœ… éå»è¨˜äº‹ã¨ã®ãƒˆãƒ³ãƒãƒŠæ¯”è¼ƒ")
    print("âœ… æ–‡ä½“ãƒ»è¡¨ç¾ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯")
    print("âœ… ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹é©åˆæ€§è©•ä¾¡")
    print("âœ… ä¿®æ­£ææ¡ˆç”Ÿæˆ")
    print("âœ… æ•¬èªèª¿æ•´ææ¡ˆ")
    print("âœ… è¡¨ç¾ãƒ¢ãƒ€ãƒ³åŒ–ææ¡ˆ")
    print("âœ… è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
    print("âœ… æ–‡æ§‹é€ åˆ†æ")
    print("âœ… ãƒˆãƒ¼ãƒ³å¤‰åŒ–è¿½è·¡")


if __name__ == "__main__":
    main()